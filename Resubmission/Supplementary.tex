
\subsection{Likelihoods arising from stochastic reaction networks}
Suppose that we are able to exactly observe the number of molecules of
each chemical species in a system which satisfies mass action
kinetics, and which can be well approximated by
\eqref{eq:RTC}. Suppose that we wish to be able to infer the value of
the rate constants of each reaction from these observations. Even with no observational noise, since the dynamics
of the system are stochastic, this still leads to a Bayesian inverse
problem where we can only infer a joint probability distributions on the
reaction parameters.

Suppose that we are in state $X(t) = X_0$. There are two independent
univariate random variables which decide when and what the next
reaction in the system is. There is the $j$th waiting time $\tau_j$ to the
next reaction, which is given by an exponential random variable
\begin{equation}\tau_j \sim \exp \left ( \frac{1}{\alpha_0(X(t))} \right ),\end{equation}
where $\alpha_0(X(t)) =\sum_{i}^{N_r} \alpha_i(X(t))$ is the total
propensity in the system. The second is a multinomial random variable $r_j$
which dictates which reaction has occurred during the $j$th reaction,
which takes the value
$i \in \{1,2,\ldots,N_r\}$ with probability
\begin{equation}\mathbb{P}(r_j = i) = \frac{\alpha_i(X(t))}{\alpha_0(X(t))}.\end{equation}
As such, in order to compute the likelihood of a particular trajectory
given a possible realisation of the reaction parameters, it is
sufficient to have access to the total time spent in each state, and
the frequency of each reaction which led to leaving each state.

From this formulation, we see that the random variables $(\tau_j, r_j)$ only depend on the states $\mathbf{X}(t_{j-1})$ and so are Markovian. This conditional independence means that we can group events together by what state the system was in when the event happened. We define two new random variables which depend on a state $\mathbf{Y} \in \mathcal{S}$, first the total time spent in state $\mathbf{Y}$,
\begin{equation}
	T(\mathbf{Y}) = \sum\limits_{j=1}^M \tau_j\; \text{I}(\mathbf{X}(t_{j-1}) = \mathbf{Y}).
\end{equation}
This random variable, $T(\mathbf{Y})$, is a sum of exponentially
distributed random variables, each with the rate $\alpha_0(\mathbf{Y};\mathbf{k})$, and hence follows the Gamma distribution,
\begin{equation}\label{eqn:chem_time_dist}
	T(\mathbf{Y}) \sim \text{Gamma}\left(\alpha=K(\mathbf{Y}),~\beta = \alpha_0(\mathbf{Y}; \mathbf{k})\right),
\end{equation}
where $K(\mathbf{Y}) = \sum\limits_{j=1}^M \text{I}(\mathbf{X}(t_{j-1}) = \mathbf{Y})$.

Similarly, we can define the reactions which occurred when the system was in state $\mathbf{Y}$ as $\mathbf{r}(\mathbf{Y}) = [r_1(\mathbf{Y}), \ldots, r_{N_r}(\mathbf{Y})]^\top$ where
\begin{equation}
	r_i(\mathbf{Y}) = \sum\limits_{j=1}^M \text{I}(r_j = i \textbf{ and }\mathbf{X}(t_{j-1}) = \mathbf{Y}).
\end{equation}
Here all the random variables $r_j$ follow the same multinomial distribution, and so
\begin{equation}\label{eqn:chem_react_dist}
	\mathbf{r}(\mathbf{Y}) \sim \text{Multinomial}(K(\mathbf{Y}),~\mathbf{p}(\mathbf{Y})). 
\end{equation}
The random variables defined in Equations~\eqref{eqn:chem_time_dist} and \eqref{eqn:chem_react_dist} are sufficient statistics for the posterior distribution $\pi(\mathbf{k}|D)$. With these definitions we define two new structures
\begin{equation}
	\mathbf{T} = [T(\mathbf{Y}_1), \dots, T(\mathbf{Y}_K)]^\top, \quad \text{and} \quad \mathbf{R} = [\mathbf{r}(\mathbf{Y}_1), \dots, \mathbf{r}(\mathbf{Y}_K)]^\top,
\end{equation}
where $K = |\mathcal{S}|$, the number of states in $\mathcal{S}$, and each state $\mathbf{Y}_i \in \mathcal{S}$ has been enumerated. We use these structures to define shorter notation,
\begin{equation}
	\mathbf{T}_i = T(\mathbf{Y}_i), \quad \mathbf{R}_{ij} = r_j(\mathbf{Y}_i), \quad \text{and} \quad \mathbf{K}_i = K(\mathbf{Y}_i).
\end{equation}

To construct the posterior distribution for the reaction rates, $\mathbf{k}$, in the chemical system, we formulate the likelihood using the sufficient statistics derived in the previous section. Due to the non-negativity of these reaction rates, we assign a Gamma prior distribution to each rate. Given the distributions in Equations~\eqref{eqn:chem_time_dist} and~\eqref{eqn:chem_react_dist} for our data, the likelihood of observing the data $\mathbf{R}$ and $\mathbf{T}$ is
\begin{equation}
	\ell(\mathbf{R}, \mathbf{T}|\mathbf{k}) \propto \prod\limits_{i=1}^K \text{Multi}(\mathbf{R}_{i\cdot}; \mathbf{K}_i, \mathbf{p}(\mathbf{Y}_i))\text{Gamma}(\mathbf{T}_i; \mathbf{K}_i, \alpha_0(\mathbf{Y}_i)),
\end{equation}
where again $\mathbf{Y}_i \in \mathcal{S}$ and the propensities
$\alpha_i$ and probabilities $p_i$ depend on the reaction rates
$\mathbf{k} = [k_1, k_2, \ldots k_{N_r}]^\top$ through the concept of
mass action kinetics given in \eqref{eq:MAK}.

Our choice of Gamma prior distributions with hyper-parameters $(a_i, b_i)$ results in the posterior distribution of the form
\begin{align}
	\pi(\mathbf{k}|\mathbf{R}, \mathbf{T}) &\propto \ell(\mathbf{R}, \mathbf{T}|\mathbf{k})
	\prod_{i=1}^{N_r} \! \text{Gamma}(k_i; a_i, b_i) \notag \\
		&\propto \exp\Bigg\{\sum\limits_{i=1}^K \Bigg[
				\mathbf{K}_i\log \alpha_0(\mathbf{Y}_i; \mathbf{k}) - \mathbf{T}_i\alpha_0(\mathbf{Y}_i; \mathbf{k}) %\notag \\
%		& \qquad\qquad\qquad
				+\sum_{j=1}^{N_r} \mathbf{R}_{ij}\log\mathbf{p}_j(\mathbf{Y}_i; \mathbf{k})
			\Bigg]  \notag\\
		&	\qquad\qquad\qquad{} + \sum_{i=1}^{N_r} ((a_i-1)\log k_i - b_ik_i)\Bigg\}. \label{eqn:chem_posterior}
\end{align}

\subsection{Approximation of likelihoods in multiscale chemical
  networks}
Suppose now that we only observe the slower variables in a
multiscale chemical system of this type. Suppose that $n_r < N_r$ is the number of slow
reactions in the system, and the slow reactions are given by $\{R_{s_1},
R_{s_2}, \ldots R_{s_{n_r}} \} \subset \{R_1, R_2, \ldots , R_{N_r}
\}$. The propensities of the slow
reactions $\alpha_{s_i}$ may depend on the value of the fast variables which is
unknown. However, the invariant distribution of the fast variables
conditioned on the slow variables in the system can be approximated
using a multiscale method, such as the QEA or the CMA, as described
briefly in Section \ref{sec:multi}. Once the approximations have been
made, we arrive at approximate \emph{effective} propensities $\bar{\alpha}_{s_i}$, which
have been averaged over the computed invariant distributions of the
fast variables. Then the approximate effective dynamics on the slow variable $S(t)$ are given by 
\begin{equation}\label{eq:RTCS}
S(t) = S(0) + \sum_{j=1}^{n_r} \nu_{s_j} \int_0^t \bar{\alpha}_{s_j}(S(s)) ds.
\end{equation}

In turn, the approximate posterior distribution on the reaction
parameters $\mathbf{k}$ is then given by
\begin{align}
	\pi(\mathbf{k}|\mathbf{R}, \mathbf{T}) &\propto \ell(\mathbf{R}, \mathbf{T}|\mathbf{k})
	\prod_{i=1}^{n_r} \! \text{Gamma}(k_i; a_i, b_i) \notag \\
		&\propto \exp\Bigg\{\sum\limits_{i=1}^K \Bigg[
				\mathbf{K}_i\log
                  \bar{\alpha}_0(\mathbf{Y}_i; \mathbf{k}) -
                  \mathbf{T}_i \bar{\alpha}_0(\mathbf{Y}_i; \mathbf{k}) %\notag \\
%		& \qquad\qquad\qquad
				+\sum_{j=1}^{n_r} \mathbf{R}_{ij}\log \bar{\mathbf{p}}_j(\mathbf{Y}_i; \mathbf{k})
			\Bigg]  \notag\\
		&	\qquad\qquad\qquad{} + \sum_{i=1}^{n_r} ((a_i-1)\log k_i - b_ik_i)\Bigg\}, \label{eq:Apos}
\end{align}
where $\bar{\alpha}_0(\mathbf{Y}_i; \mathbf{k}) = \sum_{j=1}^{n_r}
\bar{\alpha}_j(\mathbf{Y}_i; \mathbf{k})$ is the total of the
effective propensities, $n_r$ is the number of slow reactions,
$\bar{\mathbf{p}}(\mathbf{Y}_i; \mathbf{k})$ is the multiscale
approximation of the expected proportion of each slow reaction at
state $\mathbf{Y}_i$ and with reaction rates $\mathbf{k}$ and the
data is limited only to changes in the slow variable due to the
occurrence of slow reactions.